{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Writing scripts for running the ChromBPNet pipeline\n",
    "This notebook takes in a set of file paths and generates the necessary bash scripts to run through the ChromBPNet pipeline specified in the README file.\n",
    "\n",
    "This notebook makes several assumptions\n",
    "\n",
    "1. You have fragments files (BED files indicating the mapping of each read pair) for each group you want to train a model. This can be cell types, conditions, etc. or any combinations of these.\n",
    "2. You have narrowPeak files for each group you want to train a model. Most of the time this should match grouping of the fragments files.\n",
    "3. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import glob\n",
    "import yaml\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input data paths\n",
    "path_fragments = \"/cellar/users/aklie/data/datasets/HPAP/fragments\"\n",
    "path_narrowPeaks = \"/cellar/users/aklie/data/datasets/HPAP/peaks\"\n",
    "\n",
    "# Genome information\n",
    "path_genome_fasta = \"/cellar/users/aklie/data/ref/genomes/hg38/hg38.fa\"\n",
    "path_chromsizes = \"/cellar/users/aklie/data/ref/genomes/hg38/hg38.chrom.sizes\"\n",
    "path_blacklist = \"/cellar/users/aklie/data/ref/genomes/hg38/blacklist/blacklist.bed.gz\"\n",
    "path_fold_dir = \"/cellar/users/aklie/data/ref/genomes/hg38/chrombpnet/splits\"\n",
    "\n",
    "# TF motif database\n",
    "path_meme_file = \"/cellar/users/aklie/data/datasets/igvf_sc-islet_10X-Multiome/ref/motifs.meme\"\n",
    "\n",
    "# Auxiliary scripts\n",
    "path_wigToBigWig = \"/cellar/users/aklie/opt/wigToBigWig\"\n",
    "path_contribution_averaging_script = \"/cellar/users/aklie/projects/ML4GLand/chrombpnet/scripts/average_importance_h5_over_folds.py\"\n",
    "path_pfm_script = \"/cellar/users/aklie/projects/ML4GLand/chrombpnet/scripts/modisco_to_pfm.py\"\n",
    "path_meme_script = \"/cellar/users/aklie/projects/ML4GLand/chrombpnet/scripts/pfm_to_meme.py\"\n",
    "path_variant_scorer = \"/cellar/users/aklie/opt/variant-scorer/src/variant_scoring.py\"\n",
    "\n",
    "# Output path\n",
    "path_out = \"/cellar/users/aklie/data/datasets/HPAP/models\"\n",
    "os.makedirs(path_out, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Params\n",
    "name = \"HPAP\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a dictionary of fragments files for each group of interest\n",
    "fragments_dict = {}\n",
    "for f in glob.glob(f\"{path_fragments}/*.bed\"):\n",
    "    celltype = os.path.basename(f).split(\".\")[0]\n",
    "    fragments_dict[celltype] = f\n",
    "fragments_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a dictionary of narrowPeak files for each group\n",
    "narrowPeaks_dict = {}\n",
    "for f in glob.glob(f\"{path_narrowPeaks}/*.narrowPeak\"):\n",
    "    celltype = os.path.basename(f).split(\"_peaks.narrowPeak\")[0]\n",
    "    narrowPeaks_dict[celltype] = f\n",
    "narrowPeaks_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure keys are the same\n",
    "assert set(fragments_dict.keys()) == set(narrowPeaks_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the groups to train models on\n",
    "groups = list(fragments_dict.keys())\n",
    "groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_template = \"/cellar/users/aklie/projects/ML4GLand/chrombpnet/templates/negatives.txt\"\n",
    "path_scripts = \"/cellar/users/aklie/data/datasets/HPAP/bin/chrombpnet/scripts/negatives\"\n",
    "name = \"HPAP\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = 1\n",
    "celltypes = []\n",
    "fragments = []\n",
    "peaks = []\n",
    "output_dirs = []\n",
    "fold_lst = []\n",
    "for group in groups:\n",
    "    for i in range(folds):\n",
    "        outdir = f\"{path_out}/{group}/fold_{i}/negatives\"\n",
    "        os.makedirs(outdir, exist_ok=True)\n",
    "        celltypes.append(group)\n",
    "        fragments.append(fragments_dict[group])\n",
    "        peaks.append(narrowPeaks_dict[group])\n",
    "        output_dirs.append(outdir)\n",
    "        fold_lst.append(i)\n",
    "print(len(celltypes), len(fragments), len(peaks), len(output_dirs), len(fold_lst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print out celltypes in same way I would write a bash array so I can copy paste into a script\n",
    "celltypes_str=\"celltypes=(\\n\"\n",
    "for celltype in celltypes:\n",
    "    celltypes_str += f\"\\t{celltype}\\n\"\n",
    "celltypes_str += \")\"\n",
    "print(celltypes_str)\n",
    "\n",
    "# Samme for peaks\n",
    "peaks_str=\"peaks=(\\n\"\n",
    "for peak in peaks:\n",
    "    peaks_str += f\"\\t{peak}\\n\"\n",
    "peaks_str += \")\"\n",
    "print(peaks_str)\n",
    "\n",
    "# Samme for output_dirs\n",
    "output_dirs_str=\"output_dirs=(\\n\"\n",
    "for output_dir in output_dirs:\n",
    "    output_dirs_str += f\"\\t{output_dir}\\n\"\n",
    "output_dirs_str += \")\"\n",
    "print(output_dirs_str)\n",
    "\n",
    "#  Samme for fold_lst\n",
    "fold_lst_str=\"folds=(\\n\"\n",
    "for fold in fold_lst:\n",
    "    fold_lst_str += f\"\\t{fold}\\n\"\n",
    "fold_lst_str += \")\"\n",
    "print(fold_lst_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in template as a string\n",
    "template = open(path_template).read()\n",
    "template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the script\n",
    "with open(f\"{path_scripts}/{name}_negatives.sh\", \"w\") as f:\n",
    "    f.write(template.format(\n",
    "        celltypes_str,\n",
    "        peaks_str,\n",
    "        fold_lst_str,\n",
    "        output_dirs_str,\n",
    "        path_genome_fasta,\n",
    "        path_chromsizes,\n",
    "        path_fold_dir,\n",
    "        path_blacklist\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bias models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_template = \"/cellar/users/aklie/projects/ML4GLand/chrombpnet/templates/bias_pipeline.txt\"\n",
    "path_scripts = \"/cellar/users/aklie/data/datasets/HPAP/bin/chrombpnet/scripts/bias_pipeline\"\n",
    "os.makedirs(path_scripts, exist_ok=True)\n",
    "name = \"HPAP\"\n",
    "beta = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find negatives\n",
    "negatives = []\n",
    "for outdir in output_dirs:\n",
    "    group = outdir.split(\"/\")[-3]\n",
    "    negatives.append(f\"{outdir}/{group}_negatives.bed\")\n",
    "\n",
    "# Printable list\n",
    "negatives_str=\"negatives=(\\n\"\n",
    "for negative in negatives:\n",
    "    negatives_str += f\"\\t{negative}\\n\"\n",
    "negatives_str += \")\"\n",
    "print(negatives_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update output_dirs to replace \"negatives\" with bias_model/$beta\n",
    "output_dirs = [f\"{outdir.replace('/negatives', '')}/bias_model/$beta\" for outdir in output_dirs]\n",
    "\n",
    "# Same for output_dirs\n",
    "output_dirs_str=\"output_dirs=(\\n\"\n",
    "for output_dir in output_dirs:\n",
    "    output_dirs_str += f\"\\t{output_dir}\\n\"\n",
    "output_dirs_str += \")\"\n",
    "print(output_dirs_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same for fragments\n",
    "fragments_str=\"fragments=(\\n\"\n",
    "for fragment in fragments:\n",
    "    fragments_str += f\"\\t{fragment}\\n\"\n",
    "fragments_str += \")\"\n",
    "print(fragments_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in template as a string\n",
    "template = template = open(path_template).read()\n",
    "template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the script\n",
    "with open(f\"{path_scripts}/{name}_bias_pipeline.sh\", \"w\") as f:\n",
    "    f.write(template.format(\n",
    "        beta,\n",
    "        celltypes_str,\n",
    "        fragments_str,\n",
    "        peaks_str,\n",
    "        fold_lst_str,\n",
    "        negatives_str,\n",
    "        output_dirs_str,\n",
    "        path_genome_fasta,\n",
    "        path_chromsizes,\n",
    "        path_fold_dir,\n",
    "    ))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ChromBPNet models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_template = \"/cellar/users/aklie/projects/ML4GLand/chrombpnet/templates/chrombpnet_pipeline.txt\"\n",
    "path_scripts = \"/cellar/users/aklie/data/datasets/HPAP/bin/chrombpnet/scripts/chrombpnet_pipeline\"\n",
    "os.makedirs(path_scripts, exist_ok=True)\n",
    "name = \"HPAP\"\n",
    "beta = 0.3\n",
    "folds = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the bias models and put into matching list\n",
    "bias_dir = \"/cellar/users/aklie/data/datasets/HPAP/models/Beta\"\n",
    "bias_models = {}\n",
    "f = glob.glob(f\"{bias_dir}/fold_*/bias_model/{beta}/models/*bias.h5\")\n",
    "for model in f:\n",
    "    fold = model.split(\"/\")[-5]\n",
    "    bias_models[fold] = model\n",
    "bias_models_lst = [bias_models[f\"fold_{fold}\"] for fold in fold_lst]\n",
    "\n",
    "# Same for bias_models\n",
    "bias_models_str=\"bias_models=(\\n\"\n",
    "for model in bias_models_lst:\n",
    "    bias_models_str += f\"\\t{model}\\n\"\n",
    "bias_models_str += \")\"\n",
    "print(bias_models_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update output_dirs to be \n",
    "output_dirs = []\n",
    "for group in groups:\n",
    "    for i in range(folds):\n",
    "        output_dirs.append(f\"{path_out}/{group}/fold_{i}/chrombpnet/{beta}\")\n",
    "\n",
    "# Same for output_dirs\n",
    "output_dirs_str=\"output_dirs=(\\n\"\n",
    "for output_dir in output_dirs:\n",
    "    output_dirs_str += f\"\\t{output_dir}\\n\"\n",
    "output_dirs_str += \")\"\n",
    "print(output_dirs_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in template as a string\n",
    "template = open(path_template).read()\n",
    "template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the script\n",
    "with open(f\"{path_scripts}/{name}_chrombpnet_pipeline.sh\", \"w\") as f:\n",
    "    f.write(template.format(\n",
    "        beta,\n",
    "        celltypes_str,\n",
    "        fragments_str,\n",
    "        peaks_str,\n",
    "        fold_lst_str,\n",
    "        negatives_str,\n",
    "        bias_models_str,\n",
    "        output_dirs_str,\n",
    "        path_genome_fasta,\n",
    "        path_chromsizes,\n",
    "        path_fold_dir,\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "path_template = \"/cellar/users/aklie/projects/ML4GLand/chrombpnet/templates/predictions.txt\"\n",
    "path_scripts = \"/cellar/users/aklie/data/datasets/HPAP/bin/chrombpnet/scripts/predictions\"\n",
    "os.makedirs(path_scripts, exist_ok=True)\n",
    "name = \"HPAP\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find bias models\n",
    "bias_models = []\n",
    "for outdir in output_dirs:\n",
    "    f = glob.glob(f\"{outdir}/models/bias_model_scaled.h5\")[0]\n",
    "    #f = f\"{outdir}/models/bias_model_scaled.h5\"\n",
    "    group = outdir.split(\"/\")[-3]\n",
    "    bias_models.append(f)\n",
    "\n",
    "# Same for bias_models\n",
    "bias_models_str=\"bias_models=(\\n\"\n",
    "for model in bias_models:\n",
    "    bias_models_str += f\"\\t{model}\\n\"\n",
    "bias_models_str += \")\"\n",
    "print(bias_models_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find full chrombpnet models\n",
    "chrombpnet_models = []\n",
    "for outdir in output_dirs:\n",
    "    f = glob.glob(f\"{outdir}//models/chrombpnet.h5\")[0]\n",
    "    #f = f\"{outdir}/models/chrombpnet.h5\"\n",
    "    group = outdir.split(\"/\")[-3]\n",
    "    chrombpnet_models.append(f)\n",
    "\n",
    "# Same for chrombpnet_models\n",
    "chrombpnet_models_str=\"chrombpnet_models=(\\n\"\n",
    "for model in chrombpnet_models:\n",
    "    chrombpnet_models_str += f\"\\t{model}\\n\"\n",
    "chrombpnet_models_str += \")\"\n",
    "print(chrombpnet_models_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find chrombpnet_nobias models\n",
    "chrombpnet_nobias_models = []\n",
    "for outdir in output_dirs:\n",
    "    f = glob.glob(f\"{outdir}/models/chrombpnet_nobias.h5\")[0]\n",
    "    #f = f\"{outdir}/models/chrombpnet_nobias.h5\"\n",
    "    group = outdir.split(\"/\")[-3]\n",
    "    chrombpnet_nobias_models.append(f)\n",
    "\n",
    "# Same for chrombpnet_nobias_models\n",
    "chrombpnet_nobias_models_str=\"chrombpnet_nobias_models=(\\n\"\n",
    "for model in chrombpnet_nobias_models:\n",
    "    chrombpnet_nobias_models_str += f\"\\t{model}\\n\"\n",
    "chrombpnet_nobias_models_str += \")\"\n",
    "print(chrombpnet_nobias_models_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add predictions to output_dirs\n",
    "output_dirs = [f\"{outdir}/predictions\" for outdir in output_dirs]\n",
    "\n",
    "# Same for output_dirs\n",
    "output_dirs_str=\"output_dirs=(\\n\"\n",
    "for output_dir in output_dirs:\n",
    "    output_dirs_str += f\"\\t{output_dir}\\n\"\n",
    "output_dirs_str += \")\"\n",
    "print(output_dirs_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in template as a string\n",
    "template = open(path_template).read()\n",
    "template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the script\n",
    "with open(f\"{path_scripts}/{name}_predictions.sh\", \"w\") as f:\n",
    "    f.write(template.format(\n",
    "        celltypes_str,\n",
    "        peaks_str,\n",
    "        bias_models_str,\n",
    "        chrombpnet_models_str,\n",
    "        chrombpnet_nobias_models_str,\n",
    "        output_dirs_str,\n",
    "        path_genome_fasta,\n",
    "        path_chromsizes,\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Averaging predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "path_template = \"/cellar/users/aklie/projects/ML4GLand/chrombpnet/templates/average_predictions.txt\"\n",
    "path_scripts = \"/cellar/users/aklie/data/datasets/HPAP/bin/chrombpnet/scripts/predictions\"\n",
    "os.makedirs(path_scripts, exist_ok=True)\n",
    "name = \"HPAP\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group outdirs by celltype\n",
    "groups = {}\n",
    "for outdir in output_dirs:\n",
    "    group = outdir.split(\"/\")[-5]\n",
    "    if group not in groups:\n",
    "        groups[group] = []\n",
    "    groups[group].append(outdir)\n",
    "groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in template as a string\n",
    "template = open(path_template).read()\n",
    "template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the script for each celltype\n",
    "for celltype, output_dirs_celltype in groups.items():\n",
    "    bias_preds = [f\"{outdir}/{celltype}_bias.bw\" for outdir in output_dirs_celltype]\n",
    "    chrombpnet_nobias_preds = [f\"{outdir}/{celltype}_chrombpnet_nobias.bw\" for outdir in output_dirs_celltype]\n",
    "    chrombpnet_preds = [f\"{outdir}/{celltype}_chrombpnet.bw\" for outdir in output_dirs_celltype]\n",
    "    output_dir = f\"{path_out}/{celltype}/average/predictions\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    print(celltype)\n",
    "    print(output_dir)\n",
    "    bias_preds_str=\"bias_preds=(\\n\"\n",
    "    for model in bias_preds:\n",
    "        bias_preds_str += f\"\\t{model}\\n\"\n",
    "    bias_preds_str += \")\"\n",
    "    print(bias_preds_str)\n",
    "    chrombpnet_nobias_preds_str=\"chrombpnet_nobias_preds=(\\n\"\n",
    "    for model in chrombpnet_nobias_preds:\n",
    "        chrombpnet_nobias_preds_str += f\"\\t{model}\\n\"\n",
    "    chrombpnet_nobias_preds_str += \")\"\n",
    "    print(chrombpnet_nobias_preds_str)\n",
    "    chrombpnet_preds_str=\"chrombpnet_preds=(\\n\"\n",
    "    for model in chrombpnet_preds:\n",
    "        chrombpnet_preds_str += f\"\\t{model}\\n\"\n",
    "    chrombpnet_preds_str += \")\"\n",
    "    print(chrombpnet_preds_str)\n",
    "    with open(f\"{path_scripts}/{name}_{celltype}_average_predictions.sh\", \"w\") as f:\n",
    "        f.write(template.format(\n",
    "            celltype,\n",
    "            bias_preds_str,\n",
    "            chrombpnet_nobias_preds_str,\n",
    "            chrombpnet_preds_str,\n",
    "            output_dir,\n",
    "            path_wigToBigWig,\n",
    "            path_chromsizes\n",
    "        ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_template = \"/cellar/users/aklie/projects/ML4GLand/chrombpnet/templates/contributions.txt\"\n",
    "path_scripts = \"/cellar/users/aklie/data/datasets/HPAP/bin/chrombpnet/scripts/contributions\"\n",
    "os.makedirs(path_scripts, exist_ok=True)\n",
    "name = \"HPAP\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace predictions with contributions\n",
    "output_dirs = [f\"{outdir.replace('predictions', 'contributions')}\" for outdir in output_dirs]\n",
    "\n",
    "# Same for output_dirs\n",
    "output_dirs_str=\"output_dirs=(\\n\"\n",
    "for output_dir in output_dirs:\n",
    "    output_dirs_str += f\"\\t{output_dir}\\n\"\n",
    "output_dirs_str += \")\"\n",
    "print(output_dirs_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in template as a string\n",
    "template = open(path_template).read()\n",
    "template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the script\n",
    "with open(f\"{path_scripts}/{name}_contributions.sh\", \"w\") as f:\n",
    "    f.write(template.format(\n",
    "        celltypes_str,\n",
    "        peaks_str,\n",
    "        chrombpnet_nobias_models_str,\n",
    "        output_dirs_str,\n",
    "        path_genome_fasta,\n",
    "        path_chromsizes,\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Averaging contributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_template = \"/cellar/users/aklie/projects/ML4GLand/chrombpnet/templates/average_contributions.txt\"\n",
    "path_scripts = \"/cellar/users/aklie/data/datasets/HPAP/bin/chrombpnet/scripts/contributions\"\n",
    "os.makedirs(path_scripts, exist_ok=True)\n",
    "name = \"HPAP\"\n",
    "window=400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group outdirs by celltype\n",
    "groups = {}\n",
    "for outdir in output_dirs:\n",
    "    group = outdir.split(\"/\")[-5]\n",
    "    if group not in groups:\n",
    "        groups[group] = []\n",
    "    groups[group].append(outdir)\n",
    "groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in template as a string\n",
    "template = open(path_template).read()\n",
    "template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the script for each celltype\n",
    "for celltype, output_dirs_celltype in groups.items():\n",
    "    counts = [f\"{outdir}/{celltype}.counts_scores.bw\" for outdir in output_dirs_celltype]\n",
    "    profile = [f\"{outdir}/{celltype}.profile_scores.bw\" for outdir in output_dirs_celltype]\n",
    "    counts_h5 = [f\"{outdir}/{celltype}.counts_scores.h5\" for outdir in output_dirs_celltype]\n",
    "    profile_h5 = [f\"{outdir}/{celltype}.profile_scores.h5\" for outdir in output_dirs_celltype]\n",
    "    output_dir = f\"{path_out}/{celltype}/average/contributions\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    counts_str=\"counts=(\\n\"\n",
    "    for model in counts:\n",
    "        counts_str += f\"\\t{model}\\n\"\n",
    "    counts_str += \")\"\n",
    "    print(counts_str)\n",
    "\n",
    "    profile_str=\"profile=(\\n\"\n",
    "    for model in profile:\n",
    "        profile_str += f\"\\t{model}\\n\"\n",
    "    profile_str += \")\"\n",
    "    print(profile_str)\n",
    "\n",
    "    counts_h5_str=\"counts_h5=(\\n\"\n",
    "    for model in counts_h5:\n",
    "        counts_h5_str += f\"\\t{model}\\n\"\n",
    "    counts_h5_str += \")\"\n",
    "    print(counts_h5_str)\n",
    "\n",
    "    profile_h5_str=\"profile_h5=(\\n\"\n",
    "    for model in profile_h5:\n",
    "        profile_h5_str += f\"\\t{model}\\n\"\n",
    "    profile_h5_str += \")\"\n",
    "    print(profile_h5_str)\n",
    "\n",
    "    with open(f\"{path_scripts}/{name}_{celltype}_average_contributions.sh\", \"w\") as f:\n",
    "        f.write(template.format(\n",
    "            celltype,\n",
    "            counts_str,\n",
    "            profile_str,\n",
    "            counts_h5_str,\n",
    "            profile_h5_str,\n",
    "            output_dir,\n",
    "            window,\n",
    "            path_wigToBigWig,\n",
    "            path_chromsizes,\n",
    "            path_contribution_averaging_script,\n",
    "        ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# De novo motif discovery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_template = \"/cellar/users/aklie/projects/ML4GLand/chrombpnet/templates/motif_discovery.txt\"\n",
    "path_scripts = \"/cellar/users/aklie/data/datasets/HPAP/bin/chrombpnet/scripts/motifs\"\n",
    "os.makedirs(path_scripts, exist_ok=True)\n",
    "name = \"HPAP\"\n",
    "n_seqlets = 100000\n",
    "leiden_res = 2\n",
    "window = 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in template as a string\n",
    "template = open(path_template).read()\n",
    "template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find each cell types averaged contributions\n",
    "avg_contributions = []\n",
    "for group in groups:\n",
    "    avg_contributions.append(f\"{path_out}/{group}/average/contributions/{group}_counts.h5\")\n",
    "    avg_contributions.append(f\"{path_out}/{group}/average/contributions/{group}_profile.h5\")\n",
    "\n",
    "avg_contributions_str=\"input_h5s=(\\n\"\n",
    "for model in avg_contributions:\n",
    "    avg_contributions_str += f\"\\t{model}\\n\"\n",
    "avg_contributions_str += \")\"\n",
    "print(avg_contributions_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# celltypes x2\n",
    "celltypes_str=\"celltypes=(\\n\"\n",
    "for celltype in groups.keys():\n",
    "    celltypes_str += f\"\\t{celltype}\\n\"\n",
    "    celltypes_str += f\"\\t{celltype}\\n\"\n",
    "celltypes_str += \")\"\n",
    "print(celltypes_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the output dirs x 2 \n",
    "output_dirs = []\n",
    "for group in groups:\n",
    "    output_dirs.append(f\"{path_out}/{group}/average/motifs\")\n",
    "\n",
    "output_dirs_str=\"output_dirs=(\\n\"\n",
    "for model in output_dirs:\n",
    "    output_dirs_str += f\"\\t{model}\\n\"\n",
    "    output_dirs_str += f\"\\t{model}\\n\"\n",
    "output_dirs_str += \")\"\n",
    "print(output_dirs_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get one of each of type: counts and profile\n",
    "types = []\n",
    "for group in groups:\n",
    "    types.append(\"counts\")\n",
    "    types.append(\"profile\")\n",
    "types_str=\"types=(\\n\"\n",
    "for model in types:\n",
    "    types_str += f\"\\t{model}\\n\"\n",
    "types_str += \")\"\n",
    "print(types_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the script\n",
    "with open(f\"{path_scripts}/{name}_motif_discovery.sh\", \"w\") as f:\n",
    "    f.write(template.format(\n",
    "        celltypes_str,\n",
    "        avg_contributions_str,\n",
    "        output_dirs_str,\n",
    "        types_str,\n",
    "        n_seqlets,\n",
    "        leiden_res,\n",
    "        window,\n",
    "        path_meme_file,\n",
    "        path_pfm_script,\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Motif clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_template = \"/cellar/users/aklie/projects/ML4GLand/chrombpnet/templates/motif_clustering.txt\"\n",
    "path_scripts = \"/cellar/users/aklie/data/datasets/HPAP/bin/chrombpnet/scripts/motifs\"\n",
    "os.makedirs(path_scripts, exist_ok=True)\n",
    "name = \"HPAP\"\n",
    "t = 0.999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find paths to pfms\n",
    "paths_pfm = []\n",
    "for group in groups:\n",
    "    paths_pfm.append(f\"{path_out}/{group}/average/motifs/pfms/counts/{group}.counts.pfm\")\n",
    "    paths_pfm.append(f\"{path_out}/{group}/average/motifs/pfms/profile/{group}.profile.pfm\")\n",
    "paths_pfm_str=\"paths_pfm=(\\n\"\n",
    "for model in paths_pfm:\n",
    "    paths_pfm_str += f\"\\t{model}\\n\"\n",
    "paths_pfm_str += \")\"\n",
    "print(paths_pfm_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in template as a string\n",
    "template = open(path_template).read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the script\n",
    "with open(f\"{path_scripts}/{name}_motif_clustering.sh\", \"w\") as f:\n",
    "    f.write(template.format(\n",
    "        paths_pfm_str,\n",
    "        path_out + \"/motifs\",\n",
    "        t,\n",
    "        path_meme_script,\n",
    "        path_meme_file\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a master list of annotated motifs to use for hit calling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_clustered_motifs = \"/cellar/users/aklie/data/datasets/igvf_sc-islet_10X-Multiome/results/8_chrombpnet/rna_celltype_250k/motifs/cluster/cluster_key.txt\"\n",
    "path_initial_annotations = \"/cellar/users/aklie/data/datasets/igvf_sc-islet_10X-Multiome/results/8_chrombpnet/rna_celltype_250k/motifs/tfs_initial.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_annotations = pd.read_csv(path_initial_annotations, sep=\"\\t\", header=None, names=[\"cluster_name\", \"tomtom_annotation\"])\n",
    "initial_annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustered_motifs = pd.read_csv(path_clustered_motifs, sep=\"\\t\", header=None, names=[\"cluster_name\", \"pfm_names\"])\n",
    "clustered_motifs[\"pfm_names\"] = clustered_motifs[\"pfm_names\"].str.split(\",\")\n",
    "clustered_motifs = clustered_motifs.explode(\"pfm_names\")\n",
    "clustered_motifs[\"cell_type\"] = clustered_motifs[\"pfm_names\"].str.extract(r\"(SC\\..*?)\\.\")\n",
    "clustered_motifs[\"model_type\"] = clustered_motifs[\"pfm_names\"].str.extract(r\"\\.(counts|profile)\")\n",
    "clustered_motifs[\"modisco_name\"] = clustered_motifs[\"pfm_names\"].str.split(\".\").str[-2]\n",
    "clustered_motifs[\"modisco_name\"] = \"pos_patterns.\" + clustered_motifs[\"modisco_name\"]\n",
    "clustered_motifs = clustered_motifs.merge(initial_annotations, on=\"cluster_name\", how=\"left\")\n",
    "clustered_motifs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save tab-delimeted 2 column file for SC.beta counts [modisco_name, tomtom_annotation in 2nd]\n",
    "subset = clustered_motifs[clustered_motifs[\"model_type\"] == \"counts\"]\n",
    "subset = subset[subset[\"cell_type\"] == \"SC.beta\"]\n",
    "subset[\"tomtom_annotation_number\"] = subset.groupby(\"tomtom_annotation\").cumcount().astype(str).replace(\"0\", \"\")\n",
    "msk = subset[\"tomtom_annotation_number\"] != \"\"\n",
    "subset.loc[msk, \"tomtom_annotation\"] = subset.loc[msk, \"tomtom_annotation\"] + \"_\" + subset.loc[msk, \"tomtom_annotation_number\"]\n",
    "subset = subset[[\"modisco_name\", \"tomtom_annotation\"]]\n",
    "subset.to_csv(\"/cellar/users/aklie/data/datasets/igvf_sc-islet_10X-Multiome/results/8_chrombpnet/rna_celltype_250k/SC.beta/average/motifs/hits/counts/custom_motif_names.txt\", sep=\"\\t\", header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset[\"tomtom_annotation\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Motif hit calling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_template = \"/cellar/users/aklie/projects/ML4GLand/chrombpnet/templates/motif_hits.txt\"\n",
    "path_scripts = \"/cellar/users/aklie/data/datasets/HPAP/bin/chrombpnet/scripts/motifs\"\n",
    "os.makedirs(path_scripts, exist_ok=True)\n",
    "name = \"HPAP\"\n",
    "t = 0.999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell types\n",
    "celltypes_str=\"celltypes=(\\n\"\n",
    "for celltype in groups.keys():\n",
    "    celltypes_str += f\"\\t{celltype}\\n\"\n",
    "    celltypes_str += f\"\\t{celltype}\\n\"\n",
    "celltypes_str += \")\"\n",
    "print(celltypes_str)\n",
    "\n",
    "# Find peaks corresponding to modisco celltypes\n",
    "peaks = []\n",
    "for group in groups:\n",
    "    peaks.append(narrowPeaks_dict[group])\n",
    "    peaks.append(narrowPeaks_dict[group])\n",
    "peaks_str=\"peaks=(\\n\"\n",
    "for model in peaks:\n",
    "    peaks_str += f\"\\t{model}\\n\"\n",
    "peaks_str += \")\"\n",
    "print(peaks_str)\n",
    "\n",
    "# Find each cell types averaged contributions\n",
    "avg_contributions = []\n",
    "for group in groups:\n",
    "    avg_contributions.append(f\"{path_out}/{group}/average/contributions/{group}_counts.h5\")\n",
    "    avg_contributions.append(f\"{path_out}/{group}/average/contributions/{group}_profile.h5\")\n",
    "avg_contributions_str=\"input_h5s=(\\n\"\n",
    "for model in avg_contributions:\n",
    "    avg_contributions_str += f\"\\t{model}\\n\"\n",
    "avg_contributions_str += \")\"\n",
    "print(avg_contributions_str)\n",
    "\n",
    "# Find paths to modiscos\n",
    "modiscos = []\n",
    "for group in groups:\n",
    "    modiscos.append(f\"{path_out}/{group}/average/motifs/{group}.counts.modisco.h5\")\n",
    "    modiscos.append(f\"{path_out}/{group}/average/motifs/{group}.profile.modisco.h5\")\n",
    "modiscos_str=\"modiscos=(\\n\"\n",
    "for model in modiscos:\n",
    "    modiscos_str += f\"\\t{model}\\n\"\n",
    "modiscos_str += \")\"\n",
    "print(modiscos_str)\n",
    "\n",
    "# types\n",
    "types = []\n",
    "for group in groups:\n",
    "    types.append(\"counts\")\n",
    "    types.append(\"profile\")\n",
    "types_str=\"types=(\\n\"\n",
    "for model in types:\n",
    "    types_str += f\"\\t{model}\\n\"\n",
    "types_str += \")\"\n",
    "print(types_str)\n",
    "\n",
    "# output_dirs\n",
    "output_dirs = []\n",
    "for group in groups:\n",
    "    output_dirs.append(f\"{path_out}/{group}/average/motifs/hits/counts\")\n",
    "    output_dirs.append(f\"{path_out}/{group}/average/motifs/hits/profile\")\n",
    "output_dirs_str=\"output_dirs=(\\n\"\n",
    "for model in output_dirs:\n",
    "    output_dirs_str += f\"\\t{model}\\n\"\n",
    "output_dirs_str += \")\"\n",
    "print(output_dirs_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in template as a string\n",
    "template = open(path_template).read()\n",
    "template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the script\n",
    "with open(f\"{path_scripts}/{name}_motif_hits.sh\", \"w\") as f:\n",
    "    f.write(template.format(\n",
    "        celltypes_str,\n",
    "        peaks_str,\n",
    "        avg_contributions_str,\n",
    "        modiscos_str,\n",
    "        types_str,\n",
    "        output_dirs_str,\n",
    "        window,\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variant scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "path_template = \"/cellar/users/aklie/projects/ML4GLand/chrombpnet/templates/variant_scoring.txt\"\n",
    "path_scripts = \"/cellar/users/aklie/data/datasets/HPAP/bin/chrombpnet/scripts/variant_scoring\"    \n",
    "paths_variants = glob.glob(\"/cellar/users/aklie/data/ref/variants/credsets/*.bed\")\n",
    "paths_variants = [x for x in paths_variants if \"chrombpnet\" in x]\n",
    "names_variants = [\"FI_MAGIC\", \"T1D_Chiou_2021\", \"FG_MAGIC\", \"HbA1c_MAGIC\", \"2hGlu_MAGIC\"]\n",
    "os.makedirs(path_scripts, exist_ok=True)\n",
    "name = \"HPAP\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update output_dirs to be \n",
    "output_dirs = []\n",
    "for group in groups:\n",
    "    for i in range(folds):\n",
    "        output_dirs.append(f\"{path_out}/{group}/fold_{i}/chrombpnet/{beta}\")\n",
    "\n",
    "# Same for output_dirs\n",
    "output_dirs_str=\"output_dirs=(\\n\"\n",
    "for output_dir in output_dirs:\n",
    "    output_dirs_str += f\"\\t{output_dir}\\n\"\n",
    "output_dirs_str += \")\"\n",
    "print(output_dirs_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find chrombpnet_nobias models\n",
    "chrombpnet_nobias_models = []\n",
    "for outdir in output_dirs:\n",
    "    f = glob.glob(f\"{outdir}/models/chrombpnet_nobias.h5\")[0]\n",
    "    group = outdir.split(\"/\")[-3]\n",
    "    chrombpnet_nobias_models.append(f)\n",
    "\n",
    "# Same for chrombpnet_nobias_models\n",
    "chrombpnet_nobias_models_str=\"chrombpnet_nobias_models=(\\n\"\n",
    "for model in chrombpnet_nobias_models:\n",
    "    chrombpnet_nobias_models_str += f\"\\t{model}\\n\"\n",
    "chrombpnet_nobias_models_str += \")\"\n",
    "print(chrombpnet_nobias_models_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the groups to train models on\n",
    "groups = list(fragments_dict.keys())\n",
    "\n",
    "celltypes_str=\"celltypes=(\\n\"\n",
    "for celltype in groups:\n",
    "    for i in range(folds):\n",
    "        celltypes_str += f\"\\t{celltype}\\n\"\n",
    "celltypes_str += \")\"\n",
    "print(celltypes_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get template\n",
    "template = open(path_template).read()\n",
    "template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each variant list\n",
    "for path_variant, name_variant in zip(paths_variants, names_variants):\n",
    "\n",
    "    # Output dirs are the same as the chrombpnet_nobias models\n",
    "    output_dirs_str=\"output_dirs=(\\n\"\n",
    "    for output_dir in output_dirs:\n",
    "        output_dirs_str += f\"\\t{output_dir}/variant_scoring/{name_variant}\\n\"\n",
    "    output_dirs_str += \")\"\n",
    "    print(output_dirs_str)\n",
    "\n",
    "    # Write the script\n",
    "    with open(f\"{path_scripts}/{name}_{name_variant}_variant_scoring.sh\", \"w\") as f:\n",
    "        f.write(template.format(\n",
    "            celltypes_str,\n",
    "            chrombpnet_nobias_models_str,\n",
    "            output_dirs_str,\n",
    "            path_variant,\n",
    "            1234,\n",
    "            path_variant_scorer,\n",
    "            path_genome_fasta,\n",
    "            path_chromsizes,\n",
    "        ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DONE!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = 1\n",
    "celltypes = []\n",
    "peaks = []\n",
    "output_dirs = []\n",
    "fold_lst = []\n",
    "for group in groups:\n",
    "    for i in range(folds):\n",
    "        # Make a fold_{fold} directory\n",
    "        outdir = f\"{path_out}/{group}/fold_{i}/negatives\"\n",
    "        os.makedirs(outdir, exist_ok=True)\n",
    "        peakset = narrowPeaks[group]\n",
    "        celltypes.append(group)\n",
    "        peaks.append(peakset)\n",
    "        output_dirs.append(outdir)\n",
    "        fold_lst.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print out celltypes in same way I would write a bash array so I can copy paste into a script\n",
    "print(\"celltypes=(\")\n",
    "for celltype in celltypes:\n",
    "    print(f\"    {celltype}\")\n",
    "print(\")\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Samme for peaks\n",
    "print(\"peaks=(\")\n",
    "for peak in peaks:\n",
    "    print(f\"    {peak}\")\n",
    "print(\")\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Samme for output_dirs\n",
    "print(\"output_dirs=(\")\n",
    "for outdir in output_dirs:\n",
    "    print(f\"    {outdir}\")\n",
    "print(\")\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Samme for fold_lst\n",
    "print(\"folds=(\")\n",
    "for fold in fold_lst:\n",
    "    print(f\"    {fold}\")\n",
    "print(\")\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bias models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find negatives\n",
    "negatives = {}\n",
    "for outdir in output_dirs:\n",
    "    group = outdir.split(\"/\")[-3]\n",
    "    negatives[group] = f\"{outdir}/{group}_negatives.bed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update output_dirs to replace \"negatives\" with bias_model/$beta\n",
    "output_dirs = [f\"{outdir.replace(\"negatives/\", \"\")}/bias_model/$beta\" for outdir in output_dirs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same for neegatives\n",
    "print(\"negatives=(\")\n",
    "for negative in negatives.values():\n",
    "    print(f\"    {negative}\")\n",
    "print(\")\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same for output_dirs\n",
    "print(\"output_dirs=(\")\n",
    "for outdir in output_dirs:\n",
    "    print(f\"    {outdir}\")\n",
    "print(\")\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same for fragments\n",
    "print(\"fragments=(\")\n",
    "for fragment in fragments.values():\n",
    "    print(f\"    {fragment}\")\n",
    "print(\")\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prep dataset config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to template config file\n",
    "path_config = \"/cellar/users/aklie/data/datasets/igvf_sc-islet_10X-Multiome/bin/8_sequence_models/configs/prep_dataset_template.yaml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load template config\n",
    "config = yaml.safe_load(open(path_config, 'r'))\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only use these signal betas\n",
    "signal_betas = [0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_paths = []\n",
    "for i, group in enumerate(groups):\n",
    "    for signal_beta in signal_betas:\n",
    "        out_dir = os.path.join(path_out, group, \"prep_dataset\", f\"{signal_beta}\")\n",
    "        os.makedirs(out_dir, exist_ok=True)\n",
    "        curr_out = os.path.join(out_dir, f\"{group}.yaml\")\n",
    "        curr_config = config.copy()\n",
    "        curr_config[\"name\"] = group\n",
    "        curr_config[\"seqdata\"][\"bws\"] = [unstranded_bws[group]]\n",
    "        curr_config[\"seqdata\"][\"bw_names\"] = [group]\n",
    "        curr_config[\"seqdata\"][\"loci\"] = narrowPeaks[celltypes[i]]\n",
    "        curr_config[\"negatives\"][\"signal\"] = curr_config[\"seqdata\"][\"bws\"][0]\n",
    "        curr_config['negatives']['signal_beta'] = round(float(signal_beta), 1)\n",
    "        with open(curr_out, 'w') as f:\n",
    "            yaml.dump(curr_config, f)\n",
    "        print(curr_out)\n",
    "        config_paths.append(curr_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a dataframe with paths of configs in first column and output directory in second column\n",
    "df = pd.DataFrame()\n",
    "df[\"config\"] = config_paths\n",
    "df[\"out_dir\"] = [os.path.dirname(p) for p in config_paths]\n",
    "df.to_csv(\"/cellar/users/aklie/data/datasets/igvf_sc-islet_10X-Multiome/bin/8_sequence_models/metadata/prep_dataset_celltype+condition+timepoint.tsv\", sep=\"\\t\", index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bpnet fit configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to template config file\n",
    "path_config = \"/cellar/users/aklie/data/datasets/igvf_sc-islet_10X-Multiome/bin/8_sequence_models/configs/bpnet_fit_template.yaml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load template config\n",
    "config = yaml.safe_load(open(path_config, 'r'))\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab paths of seqdatas from the previous step\n",
    "seqdatas = {}\n",
    "for f in glob.glob(os.path.join(path_out, \"*\", \"prep_dataset\", \"*\", \"*.minimal.seqdata\")):\n",
    "    signal_beta = float(f.split(\"/\")[-2])\n",
    "    group = os.path.basename(f).split(\".minimal.seqdata\")[0]\n",
    "    if group not in seqdatas:\n",
    "        seqdatas[group] = {}\n",
    "    seqdatas[group][signal_beta] = f\n",
    "seqdatas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many folds?\n",
    "folds = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which signal betas to use?\n",
    "signal_betas = [0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make config files\n",
    "config_paths = []\n",
    "for i, group in enumerate(groups):\n",
    "    if group not in seqdatas:\n",
    "        continue\n",
    "    for signal_beta in signal_betas:\n",
    "        for fold in range(folds):\n",
    "            out_dir = os.path.join(path_out, group, \"bpnet_fit\", f\"fold_{fold}\", f\"{signal_beta}\")\n",
    "            os.makedirs(out_dir, exist_ok=True)\n",
    "            curr_out = os.path.join(out_dir, f\"{group}_fold_{fold}.yaml\")\n",
    "            curr_config = config.copy()\n",
    "            curr_config[\"name\"] = group\n",
    "            curr_config[\"seqdata\"][\"path\"] = seqdatas[group][signal_beta]\n",
    "            curr_config[\"seqdata\"][\"fold\"] = f\"fold_{fold}\"\n",
    "            with open(curr_out, 'w') as f:\n",
    "                yaml.dump(curr_config, f)\n",
    "            print(curr_out)\n",
    "            config_paths.append(curr_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only fold_0 configs\n",
    "config_paths = sorted([c for c in config_paths if \"fold_0\" in c])\n",
    "config_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only SC.alpha cellypes\n",
    "#config_paths = [c for c in config_paths if \"SC.alpha\" in c]\n",
    "config_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a dataframe with paths of configs in first column and output directory in second column\n",
    "df = pd.DataFrame()\n",
    "df[\"config\"] = config_paths\n",
    "df[\"out_dir\"] = [os.path.dirname(p) for p in config_paths]\n",
    "df.to_csv(\"/cellar/users/aklie/data/datasets/igvf_sc-islet_10X-Multiome/bin/8_sequence_models/metadata/bpnet_fit_celltype+condition+timepoint.tsv\", sep=\"\\t\", index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bias fit configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to template config file\n",
    "path_config = \"/cellar/users/aklie/data/datasets/igvf_sc-islet_10X-Multiome/bin/9_sequence_models/configs/bias_fit_template.yaml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load template config\n",
    "config = yaml.safe_load(open(path_config, 'r'))\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "seqdatas = {}\n",
    "for f in glob.glob(os.path.join(path_out, \"*\", \"prep_dataset\", \"*\", \"*.minimal.seqdata\")):\n",
    "    signal_beta = float(f.split(\"/\")[-2])\n",
    "    celltype = os.path.basename(f).split(\".minimal.seqdata\")[0]\n",
    "    if celltype not in seqdatas:\n",
    "        seqdatas[celltype] = {}\n",
    "    seqdatas[celltype][signal_beta] = f\n",
    "seqdatas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many folds?\n",
    "folds = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to pull out Max Negative Counts: value from the following\n",
    "reports = {}\n",
    "for f in glob.glob(os.path.join(path_out, \"*\", \"prep_dataset\", \"*\", \"*.report.html\"), recursive=True):\n",
    "    signal_beta = float(f.split(\"/\")[-2])\n",
    "    celltype = os.path.basename(f).split(\".report.html\")[0]\n",
    "    with open(f, 'r') as f:\n",
    "        content = f.read()\n",
    "        max_neg_counts = float(content.split(\"Max Negative Counts: \")[1].split(\",\")[0])\n",
    "    if celltype not in reports:\n",
    "        reports[celltype] = {}\n",
    "    reports[celltype][signal_beta] = max_neg_counts        \n",
    "reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal_betas = [0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_paths = []\n",
    "for i, celltype in enumerate(celltypes):\n",
    "    for signal_beta in signal_betas:\n",
    "        for fold in range(folds):\n",
    "            out_dir = os.path.join(path_out, celltype, \"bias_fit\", f\"fold_{fold}\", f\"{signal_beta}\")\n",
    "            os.makedirs(out_dir, exist_ok=True)\n",
    "            curr_out = os.path.join(out_dir, f\"{celltype}_fold_{fold}.yaml\")\n",
    "            curr_config = config.copy()\n",
    "            curr_config[\"name\"] = celltype\n",
    "            curr_config[\"seqdata\"][\"path\"] = seqdatas[celltype][signal_beta]\n",
    "            curr_config[\"seqdata\"][\"fold\"] = f\"fold_{fold}\"\n",
    "            config[\"seqdata\"][\"max_counts\"] = reports[celltype][signal_beta]\n",
    "            with open(curr_out, 'w') as f:\n",
    "                yaml.dump(curr_config, f)\n",
    "            print(curr_out)\n",
    "            config_paths.append(curr_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only fold_0 configs\n",
    "#config_paths = sorted([c for c in config_paths if \"fold_0\" in c])\n",
    "config_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a dataframe with paths of configs in first column and output directory in second column\n",
    "df = pd.DataFrame()\n",
    "df[\"config\"] = config_paths\n",
    "df[\"out_dir\"] = [os.path.dirname(p) for p in config_paths]\n",
    "df.to_csv(\"/cellar/users/aklie/data/datasets/igvf_sc-islet_10X-Multiome/bin/9_sequence_models/metadata/bias_fit_0.5.tsv\", sep=\"\\t\", index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chrombpnet fit configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to template config file\n",
    "path_config = \"/cellar/users/aklie/data/datasets/igvf_sc-islet_10X-Multiome/bin/9_sequence_models/configs/chrombpnet_fit_template.yaml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load template config\n",
    "config = yaml.safe_load(open(path_config, 'r'))\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab paths of seqdatas from the previous step\n",
    "seqdatas = {}\n",
    "for f in glob.glob(os.path.join(path_out, \"*\", \"prep_dataset\", \"*\", \"*.minimal.seqdata\")):\n",
    "    signal_beta = float(f.split(\"/\")[-2])\n",
    "    celltype = os.path.basename(f).split(\".minimal.seqdata\")[0]\n",
    "    if celltype not in seqdatas:\n",
    "        seqdatas[celltype] = {}\n",
    "    seqdatas[celltype][signal_beta] = f\n",
    "seqdatas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to pull\n",
    "bias_models = {}\n",
    "paths = glob.glob(os.path.join(path_out, \"*\", \"bias_fit\", \"fold_*\", \"*\", \"*.torch\"), recursive=True)\n",
    "paths = [p for p in paths if \"final\" not in p]\n",
    "for f in paths:\n",
    "    \n",
    "    # Grab celltype\n",
    "    celltype = os.path.basename(f).split(\".torch\")[0]\n",
    "    if celltype not in bias_models:\n",
    "        bias_models[celltype] = {}\n",
    "    \n",
    "    # Grab fold\n",
    "    fold = f.split(\"/\")[-3]\n",
    "    if fold not in bias_models[celltype]:\n",
    "        bias_models[celltype][fold] = {}\n",
    "\n",
    "    # Grab signal_beta\n",
    "    signal_beta = float(f.split(\"/\")[-2])\n",
    "    bias_models[celltype][fold][signal_beta] = f\n",
    "    \n",
    "bias_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many folds?\n",
    "folds = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which signal betas to use?\n",
    "signal_betas = [0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_paths = []\n",
    "for i, celltype in enumerate(celltypes):\n",
    "    for fold in bias_models[celltype]:\n",
    "        for signal_beta in signal_betas:\n",
    "            out_dir = os.path.join(path_out, celltype, \"chrombpnet_fit\", fold, f\"{signal_beta}\")\n",
    "            os.makedirs(out_dir, exist_ok=True)\n",
    "            curr_out = os.path.join(out_dir, f\"{celltype}_{fold}.yaml\")\n",
    "            curr_config = config.copy()\n",
    "            curr_config[\"name\"] = celltype\n",
    "            curr_config[\"seqdata\"][\"path\"] = seqdatas[celltype][signal_beta]\n",
    "            curr_config[\"seqdata\"][\"fold\"] = fold\n",
    "            curr_config[\"model\"][\"bias_model\"] = bias_models[celltype][fold][signal_beta]\n",
    "            with open(curr_out, 'w') as f:\n",
    "                yaml.dump(curr_config, f)\n",
    "            print(curr_out)\n",
    "            config_paths.append(curr_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only fold_0 configs\n",
    "#config_paths = sorted([c for c in config_paths if \"fold_0\" in c])\n",
    "config_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a dataframe with paths of configs in first column and output directory in second column\n",
    "df = pd.DataFrame()\n",
    "df[\"config\"] = config_paths\n",
    "df[\"out_dir\"] = [os.path.dirname(p) for p in config_paths]\n",
    "df.to_csv(\"/cellar/users/aklie/data/datasets/igvf_sc-islet_10X-Multiome/bin/9_sequence_models/metadata/chrombpnet_fit_0.5.tsv\", sep=\"\\t\", index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DONE!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11 eugene_tools",
   "language": "python",
   "name": "eugene_tools"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
